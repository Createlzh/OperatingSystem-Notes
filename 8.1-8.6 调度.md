# 8.1-8.6 调度

[TOC]

____

* 背景
  * CPU调度
  * CPU调度时间
* 调度准则
* 调度算法
* 实时调度
* 多处理器调度
* 优先级反转



____

### 背景知识

##### 上下文切换

* 切换CPU的当前任务，从一个进程/线程到另一个
* 保存当前进程/线程在PCB/TCB中的执行上下文（CPU状态）
* 读取下一个进程/线程的上下文

##### CPU调度

* 从就绪队列中挑选一个进程/线程作为CPU将要运行的下一个进程/线程

* 调度程序：挑选进程/线程的内核函数（需要一些调度策略）

* 什么时候进行调度？

  > 在进程/线程的生命周期中的什么时候进行调度？
  >
  > 从一个状态到另一个状态变化的时候会触发一次调度，尤其是`Running`相关的状态变化，如从就绪态变成运行态，从运行态变成等待状态，或者从运行态变成退出状态。
  >
  > 因为这个时候要考虑是否应该将当前的进程从CPU上撤下来，让新的进程执行。

* 内核运行调度程序的条件：（满足一条即可）

  1. 一个进程从运行状态切换到等待状态
  2. 一个进程被终结了

##### 抢占

> Linux除了内核态外还有用户态。用户程序的上下文属于用户态，系统调用和中断处理例程上下文属于内核态。在2.6 kernel以前，Linux kernel只支持用户态抢占。

* **用户态抢占：**

  * 不可抢占：（古老）

    * **非抢占式调度策略**，调度程序必须等待事件结束

      > 在这种方式下，系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时，系统方可再将处理机重新分配给另一优先权最高的进程

    * 效率不高，进程被阻塞也会占用CPU资源，直到该进程结束才会执行其他进程

  * 可以抢占：

    * **抢占式调度策略**，用户态感知不到，由操作系统完成

      > 在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原优先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程。因此，在采用这种调度算法时，是每当系统中出现一个新的就绪进程`i`时，就将其优先权`Pi`与正在执行的进程`j`的优先权`Pj`进行比较。如果`Pi≤Pj`，原进程`j`便继续执行；但如果是`Pi>Pj`，则立即停止`j`的执行，做进程切换，使`i`进程投入执行。显然，这种抢占式的优先权调度算法能更好地满足紧迫作业的要求，故而常用于要求比较严格的实时系统中，以及对性能要求较高的批处理和分时系统中。

    * 调度程序在中断被响应后执行

    * 当前的进程从运行切换到就绪，或者一个进程从等待切换到就绪

    * 当前运行的进程可以被换出

* **内核态抢占**

  > 参见博客[内核抢占](http://blog.chinaunix.net/uid-25871104-id-3331241.html)
  >
  > [Linux内核抢占的理解](https://blog.csdn.net/rikeyone/article/details/84960184)



___

### 调度原则

##### 执行模型

* 程序在`CPU突发`和`I/O`中交替

  > 对于单一进程，在执行大量计算时会使得CPU占用率高，而在进行I/O等待时CPU占用率很低。
  >
  > 对于多个进程，如何调度使得当某些进程在等待I/O时，让另外一些进程占用CPU进行计算，从而提高整体的效率？

* 每个调度决定都是关于在下一个CPU突发时，将哪个工作交给CPU

* 在时间分片机制下，线程可能在结束当前CPU突发前被迫放弃CPU



##### 调度算法的评价指标

* **CPU使用率**：CPU处于忙碌状态所占时间的百分比
* **吞吐量**：单位时间内完成的进程数量
* **周转时间**：一个进程从初始化到结束，包括所有等待时间所花费的时间
* **等待时间**：进程在就绪队列的总时间
* **响应时间**：从一个请求被提交到产生第一次响应所花费的总时间



##### 服务“快”的两种含义

* 什么是更快？
  * 传输文件时的高带宽
  * 玩游戏时的低延迟
* 与水管类比：
  * 低延迟：喝水的时候一打开水龙头立马就有水流出来（响应非常快）
  * 高带宽：给游泳池注水时希望从水龙头同时流出巨量的水，并且不介意是否存在延迟



##### 调度算法的期望效果

* 减少响应时间

  > 及时处理用户的输出并且尽快将输出提供给用户

* 减少平均响应时间的波动

  > 在交互系统中，可预测性比高差异低平均更重要

* 增加吞吐量

  > * 减少开销（操作系统开销，上下文切换）
  > * 系统资源的高效利用（CPU，I/O设备）

* 减少等待时间

  > 减少每个进程的等待时间

* `最小响应时间`和`最大吞吐量`，这两个因素往往是相矛盾的，调度算法需要取一个平衡

  > * 低延迟调度增加了交互式表现
  > * 但操作系统需要保证吞吐量不受影响
  > * `吞吐量`是操作系统的计算带宽
  > * `响应时间`是操作系统的计算延迟



##### 公平的定义

* 例1：保证每个进程占用相同的CPU时间

  > 这公平吗？如果一个用户比其他用户运行更多的进程怎么办

* 例2：保证每个进程都等待相同的时间

* 公平通常会增加平均响应时间



___

### 调度算法

##### FCFS先来先服务

* `FCFS`（First Come, First Served）

  * 使用一个`FIFO`队列：如果进程在执行中阻塞，队列中的下一个会得到CPU

* 例如

  ```ascii
  三个进程计算时间分别为12，3，3
  
  |------P1-------|--P2-|--P3-|
  任务到达顺序：P1，P2，P3
  Average response time=(12+15+18)/3=15
  
  |--P2-|--P3-|------P1-------|
  任务到达顺序：P2，P3，P1
  Average response time=(3+6+18)/3=9
  ```

* 优点：简单

* 缺点：

  * 没有考虑抢占，响应时间受到影响

  * 平均等待时间波动较大

    > 一旦前面有执行时间长的进程，后续进程的响应时间都会受到很大影响

  * 花费时间少的任务可能排在花费时间长的任务后面

  * 可能导致I/O和CPU之间的重叠处理

    * CPU密集型进程会导致I/O设备闲置，而与此同时I/O密集型进程也在等待



##### 短进程/作业优先与短剩余时间优先

* `SPN`（Shortest Process Next），`SJF`（Shortest Job First），`SRT`（Shortest Remaining Time）
  
  * 选择下一个最短的进程（短任务/进程优先）：按照预测的完成时间来将任务入队
* `SPN`/`SJF`：**非抢占式的**
  * 如果有一个新进程进入就绪队列，其执行时间比当前正在运行的进程的剩余执行时间更短，不会让当前进运行的进程被打断
  * 新进程放入就绪队列最前面，等到当前进程执行完毕后再执行
* `SRT`：**抢占式的**
  
* 如果有一个新进程进入就绪队列，其执行时间比当前正在运行的进程的剩余执行时间更短，就会进行一次抢占：把当前运行的进程挂到队列中，让新进程优先执行
  
* 优点：最优平均等待时间

  > ![最优平均等待时间](.\pics\8-1.png)

* 缺点：

  1. 可能导致饥饿，有违公平性原则

     * 连续的短任务流会使长任务饥饿
     * 短任务可用时的任何长任务的CPU时间都会增加平均等待时间

  2. 需要预测进程的执行时间，实际上不能做到

     * 怎么预估下一个CPU突发的持续时间

       > 简单的解决办法：询问用户，如果用户欺骗就杀死进程，但用户可能也不确定

* 简单预估

  ```ascii
  第n段时间内的执行时间：
  t(n) - duration of the n-th CPU burst 
  预估第n+1短时间内的执行时间：
  T(n+1) - predicted duration of the n+1st CPU burst 
  
  T(n+1) = a * t(n) + (1 - a) * T(n), for 0<= a <=1
  T(n+1) = a * t(n) + (1 - a)a * t(n-1) + (1 - a)(1 - a)a * t(n-2) + …
  ```

  

##### 最高响应比优先

* `HRRN`（Highest Response Ratio Next）
  * 在`SPN`调度算法的基础上改进，选择R值最高的进程：`R=(W+S)/S=1+W/S`

    > W：waiting time 等待时间
    >
    > S：service time 执行时间

* 优点：
  * 关注进程等待了多长时间，对交互性友好
  * 防止无限期推迟，防止饥饿现象的发生
* 缺点：
  * 算法目前**不考虑抢占**
  * 依然需要预估进程的执行时间是多少



##### 轮询

* `RR`（Round Robin）
  * 在称为为`量子`或`时间切片`的离散单元中分配处理器
  * 时间片结束时，切换到下一个准备好的进程

* 实例

  > ![轮询](.\pics\8-2.png)

* 优点：公平性原则得到了保证

* 缺点：花销大，需要进行额外的上下文切换

* 时间片的大小：

  * 时间片太大：等待时间长，极限情况下退化成`FCFS`

  * 时间片太小：反应迅速，切换频繁，吞吐量由于大量的上下文切换开销而受到影响

  * 目标：选择一个合适的时间量子

  * 经验规则：维持上下文切换开销处于1%以内

    ```ascii
    进程所需时间： 53，8，68，24
    假设上下文切换时间为0，FCFS和RR算法各自的平均等待时间是多少？
    ----------------------------------------
                 P1   P2   P3  P4  Average
    ----------------------------------------
    RR(q=1)      84   22   85  57    62     
    ----------------------------------------
    RR(q=5)      82   20   85  58    61.25 
    ----------------------------------------
    RR(q=8)      80   8    85  56    57.25  
    ----------------------------------------
    RR(q=10)     82   10   85  68    61.25  
    ----------------------------------------
    RR(q=20)     72   20   85  88    66.25  
    ----------------------------------------
    Best FCFS    32   0    85  8     31.25  
    ----------------------------------------
    Worsk FCFS   68   145  0   121   83.5   
    ----------------------------------------
    ```

    > `FCFS`的平均等待时间很大程度上取决于执行时间长的进程排在队列中的位置

* 改进方案：使用独立多级队列

  * 就绪队列被划分成独立的队列

    > e.g. 前台（交互），后台（批处理）

  * 每个队列拥有自己的调度策略

    > e.g. 前台`RR`，后台`FCFS`

  * 调度必须在队列间进行

    * 固定优先级

      > 先处理前台，然后处理后台
      >
      > 可能导致饥饿

    * 时间切片

      > 每个队列都得到一个确定的能够调度其进程的CPU总时间
      >
      > e.g. 80%给使用`RR`的前台，20%给使用`FCFS`的后台

  * **问题在于：进程动态执行过程中，不同的阶段要求不同**

    > 可能进程刚开始要求较高的交互性，但是后面需要较高的吞吐量
    >
    > 解决方案：多级反馈队列



##### 多级反馈队列

* `MFQ`（Multilevel FeedBack Queues）
  * 一个进程可以在不同的队列中移动

  * `n`级优先级：在所有级别中采取优先级调度，在每个级别中采用`RR`调度

    * 时间切片大小随着优先级级别增加而增加
    * 如果任务在当前的时间切片中没有完成，就下降到下一个优先级

  * 优点：

    * CPU密集型任务的优先级下降很快

    * I/O密集型任务停留在高优先级

      > 需要长时间占用CPU的进程，如批处理或大型计算任务，慢一些也没有关系，而I/O型的进程交互性比较强，往往需要高速响应



##### 公平共享调度

* `FSS`（Fair Share Scheduling）
  * `FFS`控制用户对系统资源的访问
  * 一些用户组比其他用户组更重要
  * 保证不重要的组无法垄断资源
  * 未使用的资源按照每个组所分配的资源的比例来分配
  * 没有达到资源使用率目标的组获得更高的优先级
* 多人多用户共享一台计算机时，在用户级别而不是进程级别，实现公平的调度
* 不同用户的进程数量不一致
* `Linux`的`CFS`（Complete Fair Scheduling）



____

### 实时调度

##### 实时系统

* 定义：正确性依赖于其时间和功能两方面的一种操作系统
* 性能指标：
  * 时间约束的及时性`deadlines`，任务必须在规定的deadline之前完成
  * 速度和平均性能相对不重要
* 主要特征：时间约束的可预测性
* 分类：
  * 强实时系统：需要在保证的时间内完成重要的任务，必须完成
  * 弱实时系统：要求重要的进程的优先级更高，尽量完成，并非必须

* 相关术语：

  > 衡量进程能否完成实时性的需求

  * **任务**（工作单元）：一次计算，一次文件读取，一次信息传递等等

  * **属性**：

    * 取得进展所需要的资源

    * **定时参数**

      > 超过Deadline则说明实时性没有得到满足
      >
      > `released`：进程处于就绪态的时间点

    ```ascii
       Released                     Absolute deadline
         |       ┌──────────────────┐       |
         ▼       | Excectution time |       ▼
    -----┼-------┼------------------┼-------┼------------
         ▲                                  ▲
         |                                  |
         └───────── Relative Deadline ──────┘
    ```

  * 周期任务：一系列相似的任务

    * 任务有规律地重复

    * 周期`p = inter-release time`（0<p）
    * 执行时间`e = 最大执行时间`（0<e<p）
    * 使用率`U = e/p`

  * **硬时限**

    * 如果错过了最后期限，可能会发生灾难性或非常严重的后果
    * 必须验证：在最坏的情况下能够满足时限吗
    * 保证确定性

  * **软时限**

    * 理想情况下，时限应该被最大满足
    * 如果时限没有被满足，那么就相应地降低要求
    * 尽最大努力去保证

    

##### 调度算法

*　静态优先级调度：优先级在一开始确定之后，就不会再发生改变

* 动态优先级调度：随着进程的执行，进程的优先级可能发生变化



##### RM速率单调调度

* `RM`（Rate Monotonic）速率单调调度
  * 最佳静态优先级调度
  * 通过周期安排优先级
  * 周期越短优先级越高
  * 执行周期最短的任务



##### EDF最早期限调度

* `EDF`（Earliest Deadline First）最早期限调度
  * 最佳的动态优先级调度
  * Deadline最早优先级越高
  * 执行Deadline最早的任务



___

### 多处理器调度

* 如何完成进程并行的调度

* 多处理器的CPU调度更加复杂
  * 多个相同的单处理器组成一个多处理器
  * 优点：负载共享
* 对称多处理器（SMP）
  * 每个处理器运行自己的调度程序
  * 需要在调度程序中同步

* 如何实现负载平衡（load balance）
* 针对单个CPU的调度算法基本上与通用调度算法一致，但是OS还需要探测不同CPU的负载情况，实现load balance



____

### 优先级反转

* 可以发生在任何**基于优先级的可抢占**的调度机制中

* 当系统内的环境强制使**高优先级任务等待低优先级任务**时发生

  * 实例

    ```ascii
          blocked by T3
          (Attempt to lock s)        s locked
                    |                  |
                    ▼                  ▼
                 ┌──┐               ┌──┐──┐
    T1 ──────────┼──┼───────────────┼──┼──┼───────
    
                          ┌────┐
    T2 ───────────────────┼────┼───────────
    
          ┌──┐──┐     ┌──┐      ┌──┐
    T3 ───┼──┼──┼─────┼──┼──────┼──┼─────────
             ▲  ▲        ▲         ▲
             |  |        |         |
      s locked  |       Preempted  s unlocked
              Preempted    by T2
              by T1
    ```

    > 优先级T1>T2>T3，但由于一开始T3占用了资源`s`，T1无法执行，必须等待T3执行完毕释放资源`s`。而此时T2抢占了T3的CPU资源，所以T1还得等T2运行完毕，系统也就因此变得不稳定。

* 解决方案：

  * 根据任务的共享资源，低优先级任务继承高优先级任务的优先级

    > 上一个例子中，由于T3与T1共享资源`s`，就将T3的优先级提到与T1一样，避免被T2抢占。让T3尽快执行完毕并释放`s`，保证T1得以在T2之前执行。

  * 优先级天花板：使资源的优先级等于所有可以锁定该资源的任务中优先级最高的那个任务的优先级

  * 除非优先级高于系统中所有被锁定的资源的优先级上限，否则任务尝试执行临界区的时候会被阻塞

  * 持有最高优先级上限信号量锁的任务，会继承被该锁所阻塞的任务的优先级

    > 资源的优先级=Max{需要该资源的进程的优先级}，占用一个资源`s`的进程`p0`，`p0`的优先级被动态提升至`s`的优先级，除非一个新进程`p1`的优先级高于`s`的优先级，否则不会发生抢占

